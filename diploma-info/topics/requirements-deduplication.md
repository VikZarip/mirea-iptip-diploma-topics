# Оценка и дедупликация требований в ИТ проектах

**Статус:** Свободно

## Краткое описание

Разработка системы, выявляющей дублирующиеся требования и оценивающей их качество в крупных ИТ-проектах с использованием анализа текста и метрик согласованности.

## Ожидаемый результат

- Веб-интерфейс или сервис для загрузки и анализа требований.
- Алгоритмы выявления дублей, конфликтов и неполноты.
- Отчёты с рекомендациями по оптимизации набора требований.
- Таблицы трассировки
- Модель кластеризации требований по смыслу.
- Панель сравнения и отчёты о совпадениях.
- Метрики полноты и точности сопоставления.

## Возможные функции/компоненты

- **Импорт**: загрузка требований в формате CSV/Excel/JSON/Markdown/Docx.
- **Аналитика**: вычисление сходства, кластеризация, выявление конфликтов, выявление неполноты.
- **Семантический индекс**: эмбеддинги предложений (BERT).
- **Дедупликация**: кластеризация и ранжирование похожих требований.
- **Визуализации**: граф связей, тепловые карты сходства.
- **Экспорт**: отчёт в PDF/Markdown, интеграция с Wiki, выгрузка в CSV/Excel/GitHub.

## Технологические ожидания

- NLP-стек: Python (spaCy, HuggingFace, FastAPI, FAISS, Sentence-Transformers).
- Backend: FastAPI/Django/Flask.
- Хранилище: PostgreSQL/ElasticSearch.
- Визуализация — Dash / Streamlit.

## Метрики успеха

- Точность выявления дублей >= 0.85 (F1-score).
- Время анализа пакета из 1000 требований < 3 мин.
- Precision/Recall > 0.8 на ручной выборке.
- Сокращение повторов > 30 %.
- Положительная оценка заказчика по тестовому сценарию.

## Основные use cases

- Проверка новых требований перед релизом.
- Навигация по архиву требований.

## Научная новизна и актуальность

- Семантический анализ требований для борьбы с дублированием.
- Гипотеза: применение контекстных моделей снижает трудозатраты аналитиков.

## Методы, модели и данные

- Sentence-BERT, тематическая кластеризация, MMR.
- Данные: открытые тикеты (Jira Apache, Mozilla bug datasets).

## Практическая польза

- Сокращает время ревью и повышает консистентность требований.

## Этапы исследований

1. Изучение методов представления требований.
2. Формирование корпуса документов (требования, user stories, Jira-тикеты).
3. Векторизация и поиск похожих текстов.
4. Кластеризация и визуализация совпадений.
5. Разработка интерфейса проверки дублей.
6. Оценка эффективности и отзывов аналитиков.

## Источники данных

- Jira Apache / Mozilla Bugzilla datasets (Kaggle).
    - https://zenodo.org/records/14253918
    - https://zenodo.org/records/15349870
- Документация open-source проектов (GitHub issues, wiki).
- Синтетические наборы требований (сгенерированные вручную).

---

## Как зарезервировать эту тему

Следуйте инструкции в главном [README.md](../../README.md#-как-зарезервировать-тему):
1. Получите код доступа у куратора
2. Создайте Issue с шаблоном "Резервация темы"
3. Укажите slug этой темы (имя файла без `.md`)
4. GitHub Actions автоматически обновит статус

---

## Закреплённые студенты

_Этот раздел заполняется автоматически при резервации темы через GitHub Issues._

